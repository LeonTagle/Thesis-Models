{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import expon\n",
    "from scipy.stats import uniform\n",
    "from scipy.optimize import root\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"IMPLICIT\" SEARCH FUNCTION\n",
    "###########################################################################\n",
    "\n",
    "def uij(ki,gammai,Vj,t,kj):\n",
    "    \"\"\"Utility patient i receives from doctor j\"\"\"\n",
    "\n",
    "    return Vj * ki - t + np.where(ki >= kj, gammai, 0)\n",
    "        \n",
    "def aij(u,λ):\n",
    "    \"\"\"Intermediate function to calculate sij\"\"\"\n",
    "\n",
    "    return np.where(u > 0, np.exp(λ*u), 0)\n",
    "                \n",
    "def logit_search(ki,gammai,Vj,t,kj,λ):    \n",
    "    \"\"\"Probability that patient i visits doctor j\"\"\"\n",
    "    #It takes the J-sized vectors of all doctors' Vj and κj as arguments\n",
    "\n",
    "    u = uij(ki,gammai,Vj,t,kj)\n",
    "    ai_total = np.sum(aij(u,λ), axis = 0)\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # To avoid pesky division by zero warning      \n",
    "        return np.where(ai_total != 0, aij(u,λ)/ai_total, 0)\n",
    "\n",
    "\n",
    "# Some auxiliary functions to set up chain rule derivatives\n",
    "\n",
    "def dlogit_search_dk(ki,gammai,Vj,t,kj,λ):\n",
    "    \"\"\"Derivative d sij / d k\"\"\"\n",
    "\n",
    "    u = uij(ki,gammai,Vj,t,kj)\n",
    "    ai_total = np.sum(aij(u,λ), axis = 0)\n",
    "    result = np.divide(\n",
    "        Vj * aij(u,λ) * np.sum(aij(u,λ))- aij(u,λ) * np.sum(Vj * aij(u,λ)),\n",
    "        (np.sum(aij(u,λ)))**2\n",
    "        )\n",
    "    \n",
    "    return np.where(ai_total != 0, result, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'sij' gives us each patient's Si vector of strategies, and if broadcast correctly it can output all patients' strategies in a single array (given numerable patients in a MC simulation), where each column is each patient’s Si, each row could be added up to a doctor's Qi.\n",
    "\n",
    "We keep it as a callable function for cases where we want the sij of a particular set of patient x doctor parameters, namely when calculating the derivative of our FOC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEq:\n",
    "    \n",
    "    def __init__(self,  I,  # Number of patients in the whole market\n",
    "                        F,  # Distribution of κi\n",
    "                        G,  # Distribution of γi\n",
    "                        t,  # Cost of visit\n",
    "                        λ,  # Logit parameter\n",
    "                        R,  # Revenue function Rj\n",
    "                        P,  # Punishment function Pj\n",
    "                        V,  # Given vector of Vj\n",
    "                        sij): # Search function\n",
    "       \n",
    "        self.I, self.F, self.G, self.t, self.λ, self.R, self.P, self.V, self.sij = I, F, G, t, λ, R, P, V, sij     # Save parameters\n",
    "    \n",
    "    def Si(self, k0, s=123):\n",
    "        \"\"\"MC simulation of the set of patient strategies out of a given set κ0 of doctor thresholds, seed s\"\"\"\n",
    "\n",
    "        I, F, G, t, λ, V, sij = self.I, self.F, self.G, self.t, self.λ, self.V, self.sij    # Unpack parameters\n",
    "        \n",
    "        rng = np.random.RandomState(s)\n",
    "        ki = F.rvs(size=I, random_state=rng).reshape((1,-1))    # Sample of patients out of distribution\n",
    "        gammai = G.rvs(size=I, random_state=rng).reshape((1,-1))\n",
    "        \n",
    "        Vj = V.reshape((-1,1))      # Reshaping doctor parameters for proper broadcasting\n",
    "        kj = k0.reshape((-1,1))\n",
    "\n",
    "        return sij(ki,gammai,Vj,t,kj,λ)\n",
    "\n",
    "    def Qi(self, k0, s=123):\n",
    "        \"\"\"Vector of expected patient demand by each doctor j out of an MC simulation of Si\"\"\"\n",
    "\n",
    "        S = self.Si(k0, s)\n",
    "\n",
    "        return np.sum(S, axis = 1)\n",
    "    \n",
    "    def Xi(self, k0, s=123):\n",
    "        \"\"\"Vector of expected certificates granted by each doctor j out of an MC simulation of Si\"\"\"\n",
    "\n",
    "        S = self.Si(k0, s)\n",
    "        F, I = self.F, self.I\n",
    "        rng = np.random.RandomState(s)\n",
    "        ki = F.rvs(size=I, random_state=rng).reshape((1,-1))\n",
    "        # We recreate the ki vector with the same seed, so it's the same\n",
    "        \n",
    "        ki_greater = np.array(ki.reshape((1,-1)) >= k0.reshape((-1,1))).astype(int) \n",
    "\n",
    "        return np.sum(S*ki_greater, axis = 1)\n",
    "    \n",
    "    def aux_func(self, func, k0):\n",
    "        \"\"\"Vector of int func(k0,gamma) dG(gamma) f(k0)\"\"\"\n",
    "\n",
    "        # We will use this function both for func = sij as well as func = ds_dk\n",
    "\n",
    "        F, G, t, λ, V = self.F, self.G, self.t, self.λ, self.V    # Unpack parameters\n",
    "\n",
    "        f = lambda x: F.pdf(x)  # Taking pdfs of our κ and γ distributions\n",
    "        g = lambda x: G.pdf(x)\n",
    "\n",
    "        s_gamma = lambda x: np.diagonal(func(k0.reshape(1,-1),x,V,t,k0,λ)) \n",
    "        # Evaluate sij at each doctor's κj, then take the diagonal, taking doctor j's sij for his own kj\n",
    "        # This is a lambda function for a given value of γ\n",
    "\n",
    "        gamma_integrand = lambda x: s_gamma(x) * g(x) # sij(γ) g(γ)\n",
    "\n",
    "        n = 101\n",
    "        x = np.linspace(G.ppf(0),G.ppf(1),n) # n-sized linspace across the domain of G\n",
    "\n",
    "        results = []\n",
    "\n",
    "        # Loop that evaluates sij(γ) g(γ) for 101 values of γ\n",
    "        for i in x:\n",
    "            result = gamma_integrand(i)\n",
    "            results.append(result)\n",
    "\n",
    "        results = np.array(results)\n",
    "\n",
    "        mc_integral = np.sum(results, axis = 0)/n\n",
    "        # By summing column wise divided by n we get a monte-carlo approximation of an integral\n",
    "\n",
    "        return - mc_integral * f(k0.reshape(-1,))\n",
    "    \n",
    "    def FOC(self, k0, dR, dP, s=123):\n",
    "        \"\"\"Out of the previous MC results, it outputs the value of evaluated FOC\"\"\"\n",
    "\n",
    "        Q = self.Qi(k0, s)\n",
    "        X = self.Xi(k0, s)\n",
    "        sij = self.sij\n",
    "        dQ_dk = self.aux_func(sij, k0)\n",
    "\n",
    "        return (dR(Q) - dP(X))*dQ_dk\n",
    "    \n",
    "    def simple_FOC(self, k0, dR, dP, s=123):\n",
    "        \"\"\"Out of the previous MC results, it outputs the value of evaluated FOC\"\"\"\n",
    "\n",
    "        Q = self.Qi(k0, s)\n",
    "        X = self.Xi(k0, s)\n",
    "\n",
    "        return (dR(Q) - dP(X))\n",
    "    \n",
    "    def dFOC_dk(self, k0, dR, dP, d2R, d2P, ds, df, s=123): #For now, we manually input the derivatives and second derivatives of interest\n",
    "\n",
    "        Q = self.Qi(k0, s)\n",
    "        X = self.Xi(k0, s)\n",
    "        sij = self.sij\n",
    "        dQ_dk = self.aux_func(sij, k0)\n",
    "        d2Q_dk = self.aux_func(ds, k0) + self.aux_func(sij, k0) * df(Q) # Double derivative of Q over κ\n",
    "\n",
    "        return (dR(Q) - dP(X))*d2Q_dk + (d2R(Q) - d2P(X))*dQ_dk\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of doctors and patients\n",
    "I = 100\n",
    "J = 50\n",
    "\n",
    "b = 5\n",
    "\n",
    "F = expon(scale=1/b)\n",
    "G = uniform\n",
    "H = uniform(scale = 1)\n",
    "\n",
    "f = lambda x: F.pdf(x)\n",
    "g = lambda x: G.pdf(x)\n",
    "\n",
    "rng = np.random.RandomState(seed=123)         # Set up number generator using seed\n",
    "V = H.rvs(size=J, random_state=rng)     # Create J-size vector of Vj values using H\n",
    "\n",
    "r = 2\n",
    "p = 1\n",
    "\n",
    "R = lambda x: r * x\n",
    "P = lambda x: p/2 * x**2\n",
    "\n",
    "dR = lambda x: r + x - x\n",
    "dP = lambda x: p * x\n",
    "\n",
    "d2R = lambda x: 0 + x - x\n",
    "d2P = lambda x: p + x - x\n",
    "\n",
    "df = lambda x: -b*f(x)\n",
    "\n",
    "k0 = np.ones(J)*0.5\n",
    "\n",
    "λ = 1\n",
    "t = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(123)\n",
    "ki = F.rvs(size=I, random_state=rng).reshape((1,-1))    # Sample of patients out of distribution\n",
    "gammai = G.rvs(size=I, random_state=rng).reshape((1,-1))\n",
    "\n",
    "V =  np.sort(V)\n",
    "Vj = V.reshape((-1,1))      # Reshaping doctor parameters for proper broadcasting\n",
    "kj = k0.reshape((-1,1))\n",
    "Vj = np.sort(Vj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogitModel = SearchEq(I, F, G, t, λ, R, P, Vj, logit_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_product_stack(k1_vals, k2_vals, J):\n",
    "    # Create meshgrid for k1_vals and k2_vals\n",
    "    k1_grid, k2_grid = np.meshgrid(k1_vals, k2_vals, indexing='ij')\n",
    "    \n",
    "    # Stack k2_grid J - 1 times along a new axis\n",
    "    k2_stacked = np.tile(k2_grid[:, :, np.newaxis], (1, 1, J - 1))\n",
    "    \n",
    "    # Combine k1_grid and stacked k2_grid along the last axis\n",
    "    cartesian_grid = np.concatenate((k1_grid[:, :, np.newaxis], k2_stacked), axis=-1)\n",
    "    \n",
    "    return cartesian_grid\n",
    "\n",
    "k1_vals = np.linspace(0,2,100)\n",
    "k2_vals = np.linspace(0,2,100)\n",
    "\n",
    "combination = cartesian_product_stack(k1_vals, k2_vals, J)\n",
    "\n",
    "Qi_combinations = np.apply_along_axis(LogitModel.Qi, axis=-1, arr=combination)\n",
    "Xi_combinations = np.apply_along_axis(LogitModel.Qi, axis=-1, arr=combination)\n",
    "FOC_condition = dR(Qi_combinations) - dP(Xi_combinations)\n",
    "FOC_condition.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[166], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m func2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39msum(LogitModel\u001b[38;5;241m.\u001b[39mFOC(x, dR, dP))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Apply the function to each vector\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_along_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXY\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Create the heatmap\u001b[39;00m\n\u001b[1;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/numpy/lib/_shape_base_impl.py:416\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m buff[ind0] \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[0;32m--> 416\u001b[0m     buff[ind] \u001b[38;5;241m=\u001b[39m asanyarray(\u001b[43mfunc1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minarr_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    418\u001b[0m res \u001b[38;5;241m=\u001b[39m transpose(buff, buff_permute)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conv\u001b[38;5;241m.\u001b[39mwrap(res)\n",
      "Cell \u001b[0;32mIn[166], line 12\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Flatten the grids and stack them as 1x2 vectors\u001b[39;00m\n\u001b[1;32m     10\u001b[0m XY \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([X\u001b[38;5;241m.\u001b[39mravel(), Y\u001b[38;5;241m.\u001b[39mravel()], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m func2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39msum(\u001b[43mLogitModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFOC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdP\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Apply the function to each vector\u001b[39;00m\n\u001b[1;32m     15\u001b[0m Z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(func2, \u001b[38;5;241m1\u001b[39m, XY)\u001b[38;5;241m.\u001b[39mreshape(X\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[159], line 88\u001b[0m, in \u001b[0;36mSearchEq.FOC\u001b[0;34m(self, k0, dR, dP, s)\u001b[0m\n\u001b[1;32m     86\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mXi(k0, s)\n\u001b[1;32m     87\u001b[0m sij \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msij\n\u001b[0;32m---> 88\u001b[0m dQ_dk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maux_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43msij\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (dR(Q) \u001b[38;5;241m-\u001b[39m dP(X))\u001b[38;5;241m*\u001b[39mdQ_dk\n",
      "Cell \u001b[0;32mIn[159], line 72\u001b[0m, in \u001b[0;36mSearchEq.aux_func\u001b[0;34m(self, func, k0)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Loop that evaluates sij(γ) g(γ) for 101 values of γ\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[0;32m---> 72\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mgamma_integrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     75\u001b[0m results \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(results)\n",
      "Cell \u001b[0;32mIn[159], line 63\u001b[0m, in \u001b[0;36mSearchEq.aux_func.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     59\u001b[0m s_gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mdiagonal(func(k0\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),x,V,t,k0,λ)) \n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Evaluate sij at each doctor's κj, then take the diagonal, taking doctor j's sij for his own kj\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# This is a lambda function for a given value of γ\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m gamma_integrand \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: s_gamma(x) \u001b[38;5;241m*\u001b[39m \u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# sij(γ) g(γ)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m101\u001b[39m\n\u001b[1;32m     66\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(G\u001b[38;5;241m.\u001b[39mppf(\u001b[38;5;241m0\u001b[39m),G\u001b[38;5;241m.\u001b[39mppf(\u001b[38;5;241m1\u001b[39m),n) \u001b[38;5;66;03m# n-sized linspace across the domain of G\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[159], line 57\u001b[0m, in \u001b[0;36mSearchEq.aux_func.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     54\u001b[0m F, G, t, λ, V \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mF, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mλ, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV    \u001b[38;5;66;03m# Unpack parameters\u001b[39;00m\n\u001b[1;32m     56\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: F\u001b[38;5;241m.\u001b[39mpdf(x)  \u001b[38;5;66;03m# Taking pdfs of our κ and γ distributions\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m s_gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mdiagonal(func(k0\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),x,V,t,k0,λ)) \n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Evaluate sij at each doctor's κj, then take the diagonal, taking doctor j's sij for his own kj\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# This is a lambda function for a given value of γ\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_distn_infrastructure.py:2033\u001b[0m, in \u001b[0;36mrv_continuous.pdf\u001b[0;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[1;32m   2031\u001b[0m output \u001b[38;5;241m=\u001b[39m zeros(shape(cond), dtyp)\n\u001b[1;32m   2032\u001b[0m putmask(output, (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mcond0)\u001b[38;5;241m+\u001b[39mnp\u001b[38;5;241m.\u001b[39misnan(x), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbadvalue)\n\u001b[0;32m-> 2033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2034\u001b[0m     goodargs \u001b[38;5;241m=\u001b[39m argsreduce(cond, \u001b[38;5;241m*\u001b[39m((x,)\u001b[38;5;241m+\u001b[39margs\u001b[38;5;241m+\u001b[39m(scale,)))\n\u001b[1;32m   2035\u001b[0m     scale, goodargs \u001b[38;5;241m=\u001b[39m goodargs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], goodargs[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2602\u001b[0m, in \u001b[0;36many\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2496\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_any_dispatcher)\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21many\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2499\u001b[0m \u001b[38;5;124;03m    Test whether any array element along a given axis evaluates to True.\u001b[39;00m\n\u001b[1;32m   2500\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2600\u001b[0m \n\u001b[1;32m   2601\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2602\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction_any_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_or\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43many\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2603\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:100\u001b[0m, in \u001b[0;36m_wrapreduction_any_all\u001b[0;34m(obj, ufunc, method, axis, out, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, \u001b[38;5;28mbool\u001b[39m, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/numpy/_core/_methods.py:65\u001b[0m, in \u001b[0;36m_any\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_any\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "J = 2\n",
    "V = H.rvs(size=J, random_state=rng)\n",
    "LogitModel = SearchEq(I, F, G, t, λ, R, P, V, logit_search)\n",
    "\n",
    "x = np.linspace(0,2,100)\n",
    "y = np.linspace(0,2,100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Flatten the grids and stack them as 1x2 vectors\n",
    "XY = np.stack([X.ravel(), Y.ravel()], axis=1)\n",
    "\n",
    "func2 = lambda x: np.sum(LogitModel.FOC(x, dR, dP))\n",
    "\n",
    "# Apply the function to each vector\n",
    "Z = np.apply_along_axis(func2, 1, XY).reshape(X.shape)\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(X, Y, Z, levels=50, cmap='viridis')\n",
    "plt.colorbar(label='Function Value')\n",
    "plt.contour(X, Y, Z, levels=[0], colors='red', linewidths=2)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Heatmap of func([x, y])')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: LogitModel.simple_FOC(x, dR, dP)\n",
    "Df = lambda x: LogitModel.dFOC_dk(x, dR, dP, d2R, d2P, dlogit_search_dk, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(f, Df, x_0, tol=1e-7, max_iter=100_000):     # As seen in QuantEcon\n",
    "    x = x_0\n",
    "\n",
    "    # Implement the zero-finding formula\n",
    "    def q(x):\n",
    "        Df_x = Df(x)  # Compute Df(x) once to avoid redundant calculations\n",
    "        return np.where(Df_x == 0, 0, x - f(x) / Df_x)\n",
    "\n",
    "    error = tol + 1\n",
    "    n = 0\n",
    "    while np.any(error > tol):\n",
    "        n += 1\n",
    "        if(n > max_iter):\n",
    "            print(\"Convergence not acheived, max iterations\")\n",
    "            break\n",
    "        y = q(x)\n",
    "        error = np.abs(x - y)\n",
    "        \n",
    "        x = y\n",
    "        x[x<0] = 0\n",
    "        error = np.where(x == 0, 0, error)\n",
    "        # Corner solutions at 0 not considered in convergence condition\n",
    "        if all(x == 0):\n",
    "            break\n",
    "    return x, error, Df(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAG(Df, f, x_0, tol=1e-7, max_iter=100_000, alpha = 0.001, beta = 0.99, decay = 0.1):\n",
    "    x = x_0\n",
    "    v = np.zeros(J)\n",
    "\n",
    "    # Implement the zero-finding formula\n",
    "    def q(x, v, alpha, beta):\n",
    "        arg = x - beta*v\n",
    "        v_new = beta*v + alpha*Df(arg)\n",
    "        x_new = x - v_new\n",
    "        return x_new, v_new\n",
    "\n",
    "    error = tol + 1\n",
    "    n = 0\n",
    "    while np.any(error > tol):\n",
    "        n += 1\n",
    "        beta = beta / (1 + decay * n)\n",
    "        if(n > max_iter):\n",
    "            print(\"Convergence not acheived, max iterations\")\n",
    "            break\n",
    "        y, v_new = q(x, v, alpha, beta)\n",
    "        error = np.abs(f(y))\n",
    "        \n",
    "        x = y\n",
    "        v = v_new\n",
    "        x[x<0] = 0\n",
    "        error = np.where(x == 0, 0, error)\n",
    "        # Corner solutions at 0 not considered in convergence condition\n",
    "        if all(x == 0):\n",
    "            break\n",
    "    return x, error, Df(x), beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(Df, x_0, tol=1e-7, max_iter=100_000, alpha=0.01, beta=0.9):\n",
    "    \"\"\"\n",
    "    Gradient Descent with Momentum and Adaptive Learning Rate Handling.\n",
    "    \"\"\"\n",
    "    x = x_0\n",
    "    v = np.zeros_like(x)\n",
    "    \n",
    "    # Update rule with momentum and adaptive learning rate\n",
    "    def q(x, v, alpha, beta):\n",
    "        v_new = beta * v + (1 - beta) * Df(x)\n",
    "        x_new = x - alpha * v_new\n",
    "        return x_new, v_new\n",
    "\n",
    "    error = tol + 1\n",
    "    n = 0\n",
    "    \n",
    "    while np.any(error > tol):\n",
    "        n += 1\n",
    "        if n > max_iter:\n",
    "            print(\"Convergence not achieved, max iterations reached\")\n",
    "            break\n",
    "\n",
    "        # Perform the gradient descent update\n",
    "        y, v_new = q(x, v, alpha, beta)\n",
    "        \n",
    "        # Update x and v\n",
    "        x = y\n",
    "        v = v_new\n",
    "        \n",
    "        # Handle corner solutions (e.g., keeping x non-negative)\n",
    "        x[x < 0] = 0\n",
    "        error = np.where(x == 0, 0, error)\n",
    "        \n",
    "        if np.all(x == 0):\n",
    "            break\n",
    "    \n",
    "    return x, error, Df(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_root(k_0,i,f):\n",
    "    \n",
    "    def subs(x,k_0,i,f):\n",
    "        k_0[i] = x[0]\n",
    "        return f(k_0)[i]\n",
    "    \n",
    "    guess = k_0[i]\n",
    "    function = lambda x: subs(x,k_0,i,f)\n",
    "\n",
    "    return root(function, guess, method='hybr')\n",
    "\n",
    "def bisect(f, x_0, tol=1e-3, max_iter=100_000):\n",
    "    x = x_0\n",
    "    \n",
    "    error = tol + 1\n",
    "    n = 0    \n",
    "    while np.any(error > tol):\n",
    "        n += 1\n",
    "        if(n > max_iter):\n",
    "            print(\"Convergence not acheived, max iterations\")\n",
    "            break\n",
    "        \n",
    "        results = np.zeros_like(x)\n",
    "        for i, x_i in enumerate(x):\n",
    "            if x_i > 0:\n",
    "                result = np.array(by_root(x, i, f).x)\n",
    "                results[i] = result[0]  # Update xi with the found root\n",
    "        x = results\n",
    "\n",
    "        x[x<0] = 0\n",
    "        error = np.abs(f(x))\n",
    "        error = np.where(x == 0, 0, error)\n",
    "        # Corner solutions at 0 not considered in convergence condition\n",
    "    return x, error, Df(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to adaptively reduce learning rate as iterations increase\n",
    "def adaptive_alpha(alpha, decay_rate, iteration):\n",
    "    return alpha / (1 + decay_rate * iteration)\n",
    "\n",
    "# Function to reduce momentum near the solution\n",
    "def adaptive_beta(beta, error, threshold=0.1):\n",
    "    if error < threshold:\n",
    "        return beta * 0.9  # Reduce momentum\n",
    "    return beta\n",
    "\n",
    "# Function to clip the gradient to avoid large updates\n",
    "def gradient_clipping(gradient, clip_value=1.0):\n",
    "    norm = np.linalg.norm(gradient)\n",
    "    if norm > clip_value:\n",
    "        return gradient * (clip_value / norm)\n",
    "    return gradient\n",
    "\n",
    "# NAG implementation with adaptive alpha, beta, and gradient clipping\n",
    "def NAG2(Df, f, x_0, tol=1e-7, max_iter=100_000, alpha=0.01, beta=0.9, decay_rate=0.001, clip_value=1.0, threshold=0.01):\n",
    "    x = np.array(x_0)  # Ensure x is a NumPy array\n",
    "    v = np.zeros_like(x)  # Initialize momentum vector\n",
    "    n = 0\n",
    "    error = np.inf  # Initialize error to start the loop\n",
    "\n",
    "    while np.linalg.norm(error) > tol:\n",
    "        n += 1\n",
    "        if n > max_iter:\n",
    "            print(\"Max iterations reached\")\n",
    "            break\n",
    "\n",
    "        # Update learning rate and momentum adaptively\n",
    "        alpha = adaptive_alpha(alpha, decay_rate, n)\n",
    "        beta = adaptive_beta(beta, np.linalg.norm(f(x)), threshold)\n",
    "\n",
    "        # Compute the gradient and apply clipping\n",
    "        gradient = Df(x)\n",
    "        clipped_gradient = gradient_clipping(gradient, clip_value)\n",
    "\n",
    "\n",
    "        v_new = beta * v + (1 - beta) * clipped_gradient\n",
    "        x_new = x - alpha * v_new\n",
    "\n",
    "        # Compute error\n",
    "        error = np.abs(f(x_new))\n",
    "        \n",
    "        # Update variables for next iteration\n",
    "        x, v = x_new, v_new\n",
    "\n",
    "        x[x<0] = 0\n",
    "        error = np.where(x == 0, 0, error)\n",
    "        \n",
    "        # Print intermediate error every 100 iterations\n",
    "        if n % 100 == 0:\n",
    "            print(f\"Iteration {n}, error: {np.linalg.norm(error)}\")\n",
    "\n",
    "    return x, error, Df(x), beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence not acheived, max iterations\n"
     ]
    }
   ],
   "source": [
    "k_guess = np.zeros(J)    \n",
    "k_original, error, Dk, beta = NAG(Df, f, k_guess, tol=1e-7, max_iter=10, alpha = 0.01, beta = 0.9, decay = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00378263, 0.00295602, 0.0032324 ,\n",
       "       0.00472959, 0.00724275, 0.00817818, 0.00847869, 0.01623935,\n",
       "       0.01811605, 0.01828636, 0.01923438, 0.02018042, 0.0206577 ])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient(Df, x_0, tol=1e-7, max_iter=10000, alpha=0.01):\n",
    "    x = np.array(x_0)\n",
    "    n = 0\n",
    "    error = np.inf\n",
    "\n",
    "    while np.any(error) > tol and n < max_iter:\n",
    "        n += 1\n",
    "        gradient = Df(x)\n",
    "        x = x - alpha * gradient\n",
    "        error = np.abs(Df(x))\n",
    "        x[x<0] = 0\n",
    "        error = np.where(x == 0, 0, error)\n",
    "\n",
    "    return x, error, gradient\n",
    "\n",
    "\n",
    "k_dot, error, Dk = gradient(Df, k, tol=1e-7, max_iter=1000, alpha=0.1)\n",
    "k_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04685613, 0.02742549, 0.04704346,\n",
       "       0.04074569, 0.02861755, 0.02677616, 0.04029885, 0.05625736,\n",
       "       0.02999037, 0.02861179, 0.04065334, 0.06000673, 0.03781208])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(k):\n",
    "    FOCs = f(k)\n",
    "    return np.max(np.abs(FOCs))\n",
    "\n",
    "\n",
    "bounds = [(0, None) for _ in range(J)]\n",
    "man = minimize(objective, k, method='TNC', jac = Df, bounds=bounds, tol=1e-3)\n",
    "a = man.x\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = k_original\n",
    "n=0\n",
    "i = 3\n",
    "max_iter = 30\n",
    "\n",
    "equality = True\n",
    "while n < max_iter:\n",
    "    n +=1\n",
    "    k_new = np.where(f(k) < 0, k + (1/(10**i)), k)\n",
    "    k_renewed = np.where(f(k_new) > 0, k, k_new)\n",
    "    k_renewed = np.where(k_original == 0, 0, k_renewed)\n",
    "    equality = np.array_equal(np.where(f(k)>0),np.where(f(k_renewed)>0))\n",
    "    if equality:\n",
    "        k = k_renewed\n",
    "    else:\n",
    "        i +=1\n",
    "    \n",
    "    \n",
    "k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = k_original\n",
    "n=0\n",
    "i = 3\n",
    "max_iter = 30\n",
    "\n",
    "equality = True\n",
    "stop_condition = np.zeros(J)\n",
    "while n < max_iter:\n",
    "    n +=1\n",
    "    k_new = np.where(f(k) < 0,\n",
    "                    k + 1/(10**i),\n",
    "                    k\n",
    "                    )\n",
    "    k_renewed = np.where(f(k_new) > 0,\n",
    "                        k,\n",
    "                        k_new)\n",
    "    stop_condition = np.where((f(k_new) > 0) & (f(k) < 0),\n",
    "                            1,\n",
    "                            stop_condition)\n",
    "    k_renewed = np.where(k_original == 0,\n",
    "                         0,\n",
    "                         k_renewed)\n",
    "    equality = np.array_equal(np.where(f(k)>0),np.where(f(k_renewed)>0))\n",
    "    if equality:\n",
    "        k = k_renewed\n",
    "    else:\n",
    "        if np.any(stop_condition[k > 0]) == 1:\n",
    "            i +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01585329,\n",
       "       0.0161452 , 0.01634267, 0.01658267, 0.01675761, 0.02480734,\n",
       "       0.02593765, 0.02768175, 0.03114876, 0.03347691, 0.03370601])"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_new = np.where(f(k) < 0, k + ((-1)**n)*(1/(10**i)), k)\n",
    "k_renewed = np.where(f(k_new) > 0, k, k_new)\n",
    "k_renewed = np.where(k_original == 0, 0, k_renewed)\n",
    "k = k_renewed\n",
    "k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
